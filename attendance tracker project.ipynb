{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c015f4-422b-4fad-a99f-97d88bf13c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6878c05-eb1e-4b10-b6c0-cac2621572aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cascade files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(\"haarcascade_smile.xml\")\n",
    "\n",
    "if face_cascade.empty() or eye_cascade.empty() or smile_cascade.empty():\n",
    "    print(\"Error loading cascade files\")\n",
    "else:\n",
    "    print(\"All cascade files loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d933a02c-4823-4512-ae41-d44322be1fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'videocapture'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mvideocapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'videocapture'"
     ]
    }
   ],
   "source": [
    "cap = cv2.videocapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba8da78-8cf7-43a0-9d57-c84b97299a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(\n",
    "            roi_gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5\n",
    "        )\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(\n",
    "                roi_color,\n",
    "                (ex, ey),\n",
    "                (ex + ew, ey + eh),\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        smiles = smile_cascade.detectMultiScale(\n",
    "            roi_gray,\n",
    "            scaleFactor=1.7,\n",
    "            minNeighbors=20\n",
    "        )\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(\n",
    "                roi_color,\n",
    "                (sx, sy),\n",
    "                (sx + sw, sy + sh),\n",
    "                (0, 0, 255),\n",
    "                2\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f98be11-0d48-4411-96f5-3e18586dbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a659ef3-7a8e-470f-8fbe-8f358089a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.31-py3-none-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting absl-py~=2.3 (from mediapipe)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sanjeevani\\anaconda3\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Collecting sounddevice~=0.5 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting flatbuffers~=25.9 (from mediapipe)\n",
      "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\sanjeevani\\anaconda3\\lib\\site-packages (from sounddevice~=0.5->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sanjeevani\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice~=0.5->mediapipe) (2.21)\n",
      "Using cached mediapipe-0.10.31-py3-none-win_amd64.whl (10.4 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached sounddevice-0.5.3-py3-none-win_amd64.whl (364 kB)\n",
      "Installing collected packages: flatbuffers, absl-py, sounddevice, mediapipe\n",
      "Successfully installed absl-py-2.3.1 flatbuffers-25.12.19 mediapipe-0.10.31 sounddevice-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c2d638-a626-42c8-b565-fa52e7c4960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed21a038-5ce7-4e6e-917f-f26717eceb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.31\n",
      "['Image', 'ImageFormat', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'tasks']\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n",
    "print(dir(mp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5200c773-7a07-4d25-9dbc-d5f156b04372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.31\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n",
    "print(hasattr(mp, \"solutions\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654915d7-f683-4c23-9c38-11a08aee7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.31\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n",
    "print(hasattr(mp, \"solutions\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89aafde-f38d-44b9-89c8-a624cac57e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdef2704-f459-4627-b97a-338fe71247ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.31\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n",
    "print(hasattr(mp, \"solutions\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c14d98e-9708-4e45-82fc-2d65a436541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.31\n",
      "['Image', 'ImageFormat', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'tasks']\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "print(mp.__version__)\n",
    "print(dir(mp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b26a88-1779-4b2c-9d8d-6e2cb307d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.11.0\n",
      "Pandas version: 2.2.2\n",
      "OpenPyXL version: 3.1.5\n",
      "All libraries are working correctly!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"OpenPyXL version:\", openpyxl.__version__)\n",
    "\n",
    "print(\"All libraries are working correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41754f22-a10a-4379-b3e2-e4d7a77e6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is working\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Camera not accessible\")\n",
    "else:\n",
    "    print(\"Camera is working\")\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901b5ac0-9ec8-4b7d-809d-f49814508164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.2\n",
      "OpenPyXL version: 3.1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"OpenPyXL version:\", openpyxl.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ec1fb9-a8b3-4afc-8778-3a2e09acac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Student Name:  namah\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance Marked\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ---------- Load Face Cascade ----------\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# ---------- Create Attendance File ----------\n",
    "file_name = \"attendance.xlsx\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "    df.to_excel(file_name, index=False)\n",
    "\n",
    "# ---------- Video Capture ----------\n",
    "cap = cv2.VideoCapture(0)\n",
    "attendance_marked = False\n",
    "\n",
    "name = input(\"Enter Student Name: \")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "        cv2.putText(frame, \"Face Detected\",\n",
    "                    (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0,255,0), 2)\n",
    "\n",
    "        # -------- Mark Attendance ONCE --------\n",
    "        if not attendance_marked:\n",
    "            now = datetime.now()\n",
    "            date = now.strftime(\"%d-%m-%Y\")\n",
    "            time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "            df = pd.read_excel(file_name)\n",
    "            df.loc[len(df)] = [name, date, time]\n",
    "            df.to_excel(file_name, index=False)\n",
    "\n",
    "            attendance_marked = True\n",
    "            print(\"Attendance Marked\")\n",
    "\n",
    "    cv2.imshow(\"Face Attendance System\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38071d16-c459-4862-9b49-d391984b2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Student Name:  namah\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance Marked Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------- Face Cascade ----------\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# ---------- Attendance File ----------\n",
    "file_name = \"attendance.xlsx\"\n",
    "if not os.path.exists(file_name):\n",
    "    pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"]).to_excel(file_name, index=False)\n",
    "\n",
    "# ---------- Camera ----------\n",
    "cap = cv2.VideoCapture(0)\n",
    "attendance_marked = False\n",
    "name = input(\"Enter Student Name: \")\n",
    "\n",
    "# ---------- Background Subtractor for Hand ----------\n",
    "bg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ---------- Face Detection ----------\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    face_detected = len(faces) > 0\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "    # ---------- Hand Detection ----------\n",
    "    fgmask = bg.apply(frame)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    hand_detected = False\n",
    "\n",
    "    if contours:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(max_contour) > 3000:\n",
    "            hand_detected = True\n",
    "            cv2.drawContours(frame, [max_contour], -1, (255,0,0), 2)\n",
    "\n",
    "    # ---------- Attendance Logic ----------\n",
    "    if face_detected and hand_detected and not attendance_marked:\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"%d-%m-%Y\")\n",
    "        time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        df = pd.read_excel(file_name)\n",
    "        df.loc[len(df)] = [name, date, time]\n",
    "        df.to_excel(file_name, index=False)\n",
    "\n",
    "        attendance_marked = True\n",
    "        print(\"Attendance Marked Successfully\")\n",
    "\n",
    "    # ---------- Display Status ----------\n",
    "    cv2.putText(frame, f\"Face: {face_detected}\",\n",
    "                (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "    cv2.putText(frame, f\"Hand: {hand_detected}\",\n",
    "                (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Advanced Attendance System\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e7beaad-8b80-4fad-8385-484a4e4b97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"attendance.xlsx\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "    df.to_excel(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409b7822-d454-4549-8f1f-5c338a5daf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"ATTENDENCE.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d5e92f2-7d2e-4aad-b281-5fd95b975c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [name, date, time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf2dc539-303c-4f1e-9bd4-8a3dc1a5bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Student Name:  sanjeevani\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Attendance Marked Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import winsound\n",
    "\n",
    "# ---------------- FACE CASCADE ----------------\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# ---------------- EXCEL FILE ----------------\n",
    "file_name = \"attendance.xlsx\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "    df.to_excel(file_name, index=False)\n",
    "\n",
    "# ---------------- VIDEO CAPTURE ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "attendance_marked = False\n",
    "\n",
    "name = input(\"Enter Student Name: \")\n",
    "\n",
    "# ---------------- HAND DETECTION ----------------\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # -------- FACE DETECTION --------\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    face_detected = False\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_detected = True\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Face Detected\",\n",
    "                    (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0,255,0), 2)\n",
    "\n",
    "    # -------- HAND DETECTION --------\n",
    "    fgmask = bg_subtractor.apply(frame)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    hand_detected = False\n",
    "\n",
    "    if contours:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(max_contour) > 3000:\n",
    "            hand_detected = True\n",
    "            cv2.drawContours(frame, [max_contour], -1, (255, 0, 0), 2)\n",
    "\n",
    "    # -------- ATTENDANCE LOGIC --------\n",
    "    if face_detected and not attendance_marked:\n",
    "\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"%d-%m-%Y\")\n",
    "        time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        df = pd.read_excel(file_name)\n",
    "        df.loc[len(df)] = [name, date, time]\n",
    "        df.to_excel(file_name, index=False)\n",
    "\n",
    "        attendance_marked = True\n",
    "        print(\"âœ… Attendance Marked Successfully\")\n",
    "\n",
    "        # ðŸ”” Beep confirmation (ONCE)\n",
    "        winsound.Beep(1000, 500)\n",
    "\n",
    "    # -------- DISPLAY STATUS --------\n",
    "    cv2.putText(frame, f\"Face: {face_detected}\",\n",
    "                (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Hand: {hand_detected}\",\n",
    "                (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face + Gesture Attendance System\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f21c60a-a313-4def-959e-febe20b5de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [NAME , DATE, TIME]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"ATTENDENCE.xlsx\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca20eb9e-2e99-419a-b7d5-c7b5daac74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name        Date      Time\n",
      "0   sanjeevani   25-12-2025  18:09:07\n",
      "1         namah  25-12-2025  18:09:59\n",
      "2    sanjeevani  25-12-2025  18:12:47\n",
      "3         namah  25-12-2025  18:16:45\n",
      "4    sanjeevani  25-12-2025  18:27:45\n",
      "5    sanjeevani  25-12-2025  18:34:04\n",
      "6          amit  25-12-2025  18:34:50\n",
      "7     Test User  25-12-2025  18:30:00\n",
      "8          vani  25-12-2025  18:42:11\n",
      "9     Test User  25-12-2025  18:30:00\n",
      "10   sanjeevani  25-12-2025  18:44:03\n",
      "11    Test User  25-12-2025  18:30:00\n",
      "12   sanjeevani  25-12-2025  18:44:42\n",
      "13    Test User  25-12-2025  18:30:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"attendance.xlsx\")\n",
    "df.loc[len(df)] = [\"Test User\", \"25-12-2025\", \"18:30:00\"]\n",
    "df.to_excel(\"attendance.xlsx\", index=False)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2428b-8240-4605-a7e3-981911b791fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
